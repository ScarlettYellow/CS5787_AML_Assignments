{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"input/split_train.csv\")\n",
    "x_train=train.drop('target',axis=1)#dataframe with index\n",
    "y_train=train.target\n",
    "\n",
    "test=pd.read_csv(\"input/dev.csv\")\n",
    "x_test=test.drop('target',axis=1)#dataframe with index\n",
    "y_test=test.target\n",
    "\n",
    "tweettoken = TweetTokenizer(strip_handles=True, reduce_len=True) # word segmentation\n",
    "stemmer=PorterStemmer() # stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pre=[]\n",
    "test_pre=[]\n",
    "def preprocess(t,kpc):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    tee=url.sub(r'',t)\n",
    "    tee=re.sub('[^a-zA-Z]',\" \",tee)\n",
    "    tee=tee.lower()\n",
    "    res=tweettoken.tokenize(tee)\n",
    "    for i in res:\n",
    "        if i in stopwords.words('english'):\n",
    "            res.remove(i)\n",
    "    rest=[]\n",
    "    for k in res:\n",
    "        rest.append(stemmer.stem(k))\n",
    "    ret=\" \".join(rest)\n",
    "    if kpc==1:\n",
    "        train_pre.append(ret)\n",
    "    elif kpc==0:\n",
    "        test_pre.append(ret)\n",
    "\n",
    "def splitpro(t,q,m):\n",
    "         for j in range(q):\n",
    "                 preprocess(t[\"text\"].iloc[j],m)\n",
    "                 \n",
    "splitpro(x_train,5329,1)\n",
    "splitpro(x_test,2284,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question d: Bag of Words model \n",
    "\n",
    "description: use bag of words model for text vectorization\n",
    "\n",
    "d-1: build the bag of words feature vectors for both the train and dev sets, and report the total number of features in these vectors.\n",
    "\n",
    "- answer: total number of features = 2991.\n",
    "- codes: see the codes and results in **Cell [4], [5]**.\n",
    "\n",
    "d-2: decide on an appropriate threshold M , and discuss how you made this decision.\n",
    "\n",
    "- answer: best threshold M=3. To decide on the best M, I use F1 Score to be the metric, i.e., the value that leads to the highest F1 Score is my best M. I set the value of M from 1 to 10 and run each of the four classification models respectively. Results show that when M=3, the Bernoulli Naive Bayes model gets the highest F1 Score (0.7611518915866743) among all models. \n",
    "- codes: see codes and results in **Cell [15], [16], [17], [18]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d-1: use bag of words model on train set.\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=3,\n",
    "                             binary=True) #instantiate the CountVectorizer class, set M=3\n",
    "train_corpus = train_pre\n",
    "\n",
    "train_bow_vectors = vectorizer.fit_transform(train_corpus) #use fit() to create index, transform each document into a word frequency vector\n",
    "print(type(train_bow_vectors)) #type: sparse vector\n",
    "#print (train_bow_vectors)\n",
    "\n",
    "train_bow_vectors = train_bow_vectors.toarray()\n",
    "print (train_bow_vectors)\n",
    "print(type(train_bow_vectors)) #type: np array\n",
    "\n",
    "train_bow_voca_list = vectorizer.get_feature_names() #generate corpus into a vocabulary list\n",
    "train_bow_voca_dic = vectorizer.vocabulary_\n",
    "print(train_bow_voca_list[:50])\n",
    "print(list(train_bow_voca_dic.items())[:50])\n",
    "#print('vocabulary list of trainset:', train_bow_voca_list)\n",
    "#print( 'vocabulary dic of trainset:', train_bow_voca_dic)\n",
    "\n",
    "print(train_bow_vectors.sum(axis=0)) #count each word' frequency in the corpus\n",
    "\n",
    "X1 = train_bow_vectors.shape\n",
    "print (X1)\n",
    "train_bow_feature_num = X1[1] #vector length/number of features\n",
    "print ('total number of features in trainset:', train_bow_feature_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d-1: use bag of words model on dev set.\n",
    "\n",
    "test_corpus = test_pre\n",
    "\n",
    "test_bow_vectors = vectorizer.transform(test_corpus) #use the same set of tokens as trainset, transform each document into a word frequency vector\n",
    "print(type(test_bow_vectors)) #type: sparse vector\n",
    "#print (test_bow_vectors)\n",
    "\n",
    "test_bow_vectors = test_bow_vectors.toarray()\n",
    "print (test_bow_vectors)\n",
    "print(type(test_bow_vectors)) #type: np array\n",
    "\n",
    "test_bow_voca_list = vectorizer.get_feature_names() #generate corpus into a vocabulary list\n",
    "test_bow_voca_dic = vectorizer.vocabulary_\n",
    "print(test_bow_voca_list[:50])\n",
    "print(list(test_bow_voca_dic.items())[:50])\n",
    "#print('vocabulary list of dev set:', test_bow_voca_list)\n",
    "#print( 'vocabulary dic of dev set:', test_bow_voca_dic)\n",
    "\n",
    "print(test_bow_vectors.sum(axis=0)) #count each word' frequency in the corpus\n",
    "\n",
    "X2 = test_bow_vectors.shape\n",
    "print (X2)\n",
    "test_bow_feature_num = X2[1] #vector length/number of features\n",
    "print ('total number of features in dev set:', test_bow_feature_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question e: Implement a naive Bayes classifier - BernoulliNB Naive Bayes\n",
    "\n",
    "e-1: implement the BernoulliNB Naive Bayes classifier, without using any existing machine learning libraries. \n",
    "\n",
    "- codes: see the codes in **Cell [6]**.\n",
    "\n",
    "e-2: Train this classifier on the train set, and report its mean F 1-score on the dev set.\n",
    "\n",
    "- codes: see the codes and results in **Cell [7]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e-1: implement the BernoulliNB Naive Bayes classifier, without using any existing machine learning libraries.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class Bernoulli_NaiveBayes:\n",
    "\n",
    "    def __init__(self):   \n",
    "        self.alpha = 1 # set smoothing factor=1(Laplace Smoothing), to avoid zero probability problems  \n",
    "\n",
    "    def _cal_prior_prob_log(self, y, classes): # calculate the logarithm of prior probability of each class, P(y=c_k)\n",
    "        self.classes = np.unique(y)\n",
    "        class_num = len(self.classes) #count the number of possible types of y\n",
    "        sample_num = len(y)\n",
    "        \n",
    "        c_num = np.count_nonzero(y == classes[:, None], axis=1) #count sample amount of each class\n",
    "        prior_prob = (c_num + self.alpha) / (sample_num + class_num * self.alpha) #calculate prior probabilities(add smoothing correction)\n",
    "        prior_prob_log = np.log(prior_prob) #calculate logarithm\n",
    "        \n",
    "        return prior_prob_log\n",
    "    \n",
    "    def _cal_condi_prob_log(self, X, y, classes): #calculate the logarithm of all conditional probabilities P(x^(j)|y=c_k)\n",
    "        \n",
    "        n = (X.shape)[1]\n",
    "        K = len(classes)\n",
    "        \n",
    "        #create an empty multidimensional array\n",
    "        #prob_log: logarithmic matrix of two conditional probabilities\n",
    "        condi_prob_log = np.empty((2, K, n)) \n",
    "        \n",
    "        for k, c in enumerate(classes):\n",
    "            X_c = X[np.equal(y, c)] #acquire all samples of class c_k\n",
    "            total_num = len(X_c)\n",
    "            num_f1 = np.count_nonzero(X_c, axis=0) #count the number of samples of which feature value is 1\n",
    "            condi_prob_f1 = (num_f1 + self.alpha) / (total_num + self.alpha * 2) #calculate conditional probability P(x^(j)=1|y=c_k)\n",
    "            \n",
    "            #calculate and store logarithm into matrix\n",
    "            #prob_log[0]: store all values of log(P(x^(j)=0|y=c_k))\n",
    "            #prob_log[1]: store all values of log(P(x^(j)=1|y=c_k))\n",
    "            condi_prob_log[0, k] = np.log(1 - condi_prob_f1) \n",
    "            condi_prob_log[1, k] = np.log(condi_prob_f1) \n",
    "            \n",
    "        return condi_prob_log\n",
    "   \n",
    "    def train(self, x_train, y_train): #train the model\n",
    "        self.classes = np.unique(y_train) #acquire all classes  \n",
    "        self.prior_prob_log = self._cal_prior_prob_log(y_train, self.classes) #calculate and store the logarithm of all prior probabilities\n",
    "        self.condi_prob_log = self._cal_condi_prob_log(x_train, y_train, self.classes) #calculate and store the logarithm of all conditional probabilities\n",
    "\n",
    "    def _predict_single_sample(self, x): #predict the label of single sample\n",
    "\n",
    "        K = len(self.classes)\n",
    "        po_prob_log = np.empty(K) #create an empty multidimensional array\n",
    "        \n",
    "        index_f1 = x == 1 #acquire index of feature value=1 \n",
    "        index_f0 = ~index_f1 #acquire index of feature value=0\n",
    "\n",
    "        for k in range(K): #iterate each class\n",
    "            #calculate the logarithm of the numerator of the posterior probability\n",
    "            po_prob_log[k] = self.prior_prob_log[k] \\\n",
    "                                + np.sum(self.condi_prob_log[0, k][index_f0]) \\\n",
    "                                + np.sum(self.condi_prob_log[1, k][index_f1])\n",
    "\n",
    "        label = np.argmax(po_prob_log) #get the class with the highest posterior probability\n",
    "        return label\n",
    "\n",
    "    def predict(self, X): #predict samples (include single sample)\n",
    "        \n",
    "        if X.ndim == 1: #if only predict single sample (the dimension of the array = 1), invoke _predict_single_sample()\n",
    "            return self._predict_single_sample(X) \n",
    "        else:\n",
    "            #if predict multiple samples, loop call _predict_single_sample() and return a list of the predicted results \n",
    "            labels = []\n",
    "            for j in range(X.shape[0]):\n",
    "                label = self._predict_single_sample(X[j])\n",
    "                labels.append(label)\n",
    "            return labels\n",
    "        \n",
    "    def cal_f1_score(self,true,predict):\n",
    "        \n",
    "        true = list(true)\n",
    "        num = len(true)\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        TN = 0\n",
    "        FN = 0\n",
    "        \n",
    "        for i in range(num):               \n",
    "            if true[i] != predict[i]:\n",
    "                if true[i] == 1:\n",
    "                    FN += 1\n",
    "                else:\n",
    "                    FP += 1\n",
    "            else:\n",
    "                if true[i] == 1:\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    TN += 1\n",
    "\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        F1_Score = 2 * (precision * recall) / (precision + recall)\n",
    "        return F1_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e-2: Train the Bernoulli_NaiveBayes classifier on the train set, and report its mean F 1-score on the dev set.\n",
    "\n",
    "x_train = train_bow_vectors\n",
    "y_train = np.array(y_train)\n",
    "x_test = test_bow_vectors\n",
    "\n",
    "BernoulliNB = Bernoulli_NaiveBayes()\n",
    "BernoulliNB.train(x_train,y_train)\n",
    "y_pred = BernoulliNB.predict(x_test)\n",
    "\n",
    "print (BernoulliNB.cal_f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question i: N-gram model\n",
    "\n",
    "description: use N-gram model for text vectorization\n",
    "\n",
    "i-1: Using N = 2, construct feature representations of the tweets in the train and dev tweets.\n",
    "\n",
    "- answer: total number of features = 4849.\n",
    "- codes: see the codes and results in **Cell [8], [9]**.\n",
    "\n",
    "i-2: Randomly sample 10 2-grams from your vocabulary, and print them out. \n",
    "\n",
    "- codes: see the codes and results in **Cell [10]**.\n",
    "\n",
    "i-3: Choose a threshold M, and only include symbols in the vocabulary that occur in at least M different tweets in the train set. Discuss how you chose the threshold M.\n",
    "\n",
    "- answer: best threshold M=3. To decide on the best M, I use F1 Score to be the metric, i.e., the value that leads to the highest F1 Score is my best M. I set the value of M from 1 to 10 and run each of the four classification models respectively. Results show that when M=3, the Non-linear SVM model gets the highest F1 Score (0.7555040556199305) among all models. \n",
    "- codes: see the codes and results in **Cell [19], [20], [21], [22]**.\n",
    "\n",
    "i-4: Repeat parts (e)-(h), and report the results. \n",
    "\n",
    "- codes: see the codes and results in **Cell [11], [12], [13], [14]**.\n",
    "\n",
    "i-5: Do these results differ significantly from those using the bag of words model? Discuss what this implies about the task.\n",
    "\n",
    "- answer: According to the results printed in Cell [15]~[22], the F1 scores of using the N-gram model are generally slightly lower than those using the bag of words model. The range of this difference is not significantly large, not greater than 0.04. This implies that Bag of Words model and N-gram model have similar performance on this short text classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i-1: use N-gram model (N=2) on train set.\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=3,\n",
    "                             ngram_range=(1,2),\n",
    "                             binary=True) #instantiate the CountVectorizer class, set M=3\n",
    "\n",
    "train_corpus = train_pre\n",
    "train_ng_vectors = vectorizer.fit_transform(train_corpus) #use fit() to create index,transform each document into a word frequency vector\n",
    "print(type(train_ng_vectors)) #type: sparse vector\n",
    "#print (train_ng_vectors)\n",
    "\n",
    "train_ng_vectors = train_ng_vectors.toarray()\n",
    "print (train_ng_vectors)\n",
    "print(type(train_ng_vectors)) #type: np array\n",
    "\n",
    "train_ng_voca_list = vectorizer.get_feature_names() #generate corpus into a vocabulary list\n",
    "train_ng_voca_dic = vectorizer.vocabulary_\n",
    "print(train_ng_voca_list[:50])\n",
    "print(list(train_ng_voca_dic.items())[:50])\n",
    "#print('vocabulary list of trainset:', train_ng_voca_list)\n",
    "#print( 'vocabulary dic of trainset:', train_ng_voca_dic)\n",
    "\n",
    "print(train_ng_vectors.sum(axis=0)) #count each word' frequency in the corpus\n",
    "\n",
    "X3 = train_ng_vectors.shape\n",
    "print (X3)\n",
    "train_ng_feature_num = X3[1] #vector length/number of features\n",
    "print ('total number of features in trainset:', train_ng_feature_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i-1: use N-gram model (N=2) on dev set.\n",
    "\n",
    "test_corpus = test_pre\n",
    "test_ng_vectors = vectorizer.transform(test_corpus) #use the same set of tokens as trainset, transform each document into a word frequency vector\n",
    "print(type(test_ng_vectors)) #type: sparse vector\n",
    "#print (test_ng_vectors)\n",
    "\n",
    "test_ng_vectors = test_ng_vectors.toarray()\n",
    "print (test_ng_vectors)\n",
    "print(type(test_ng_vectors)) #type: np array\n",
    "\n",
    "test_ng_voca_list = vectorizer.get_feature_names() #generate corpus into a vocabulary list\n",
    "test_ng_voca_dic = vectorizer.vocabulary_\n",
    "print(test_ng_voca_list[:50])\n",
    "print(list(test_ng_voca_dic.items())[:50])\n",
    "#print('vocabulary list of trainset:', test_ng_voca_list)\n",
    "#print( 'vocabulary dic of trainset:', test_ng_voca_dic)\n",
    "\n",
    "print(test_ng_vectors.sum(axis=0)) #count each word' frequency in the corpus\n",
    "\n",
    "X4 = test_ng_vectors.shape\n",
    "print (X4)\n",
    "test_ng_feature_num = X4[1] #vector length/number of features\n",
    "print ('total number of features in dev set:', test_ng_feature_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i-2: Randomly sample 10 2-grams from your vocabulary, and print them out. \n",
    "\n",
    "import random \n",
    "\n",
    "slice = []\n",
    "for word in random.sample(test_ng_voca_list,100):\n",
    "    if bool(' ' in word) == True:\n",
    "        slice.append(word)\n",
    "        if len(slice) == 10:\n",
    "            break\n",
    "print (slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i-4: use N-gram model, repeat parts (e)-(h), and report the results.\n",
    "\n",
    "# 1.Bernoulli NaiveBayes model\n",
    "y_train = np.array(y_train)\n",
    "BernoulliNB = Bernoulli_NaiveBayes()\n",
    "BernoulliNB.train(train_ng_vectors,y_train)\n",
    "y_pred = BernoulliNB.predict(test_ng_vectors)\n",
    "print (BernoulliNB.cal_f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i-4: use N-gram model, repeat parts (e)-(h), and report the results.\n",
    "\n",
    "# 2.LR model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "LR = LogisticRegression()\n",
    "LR.fit(train_ng_vectors,y_train)\n",
    "predict_lr=LR.predict(test_ng_vectors)\n",
    "print(f1_score(y_test,predict_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i-4: use N-gram model, repeat parts (e)-(h), and report the results.\n",
    "\n",
    "# 3.Linear SVM model\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "lsvm_model=LinearSVC(C=0.1)\n",
    "lsvm_model.fit(train_ng_vectors,y_train)\n",
    "predict_lsvm=lsvm_model.predict(test_ng_vectors)\n",
    "print(f1_score(y_test,predict_lsvm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i-4: use N-gram model, repeat parts (e)-(h), and report the results.\n",
    "\n",
    "# 4.Non-linear SVM model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "SVM=SVC(C=1,kernel='rbf',gamma=0.1)\n",
    "SVM.fit(train_ng_vectors,y_train)\n",
    "predict_svm=SVM.predict(test_ng_vectors)\n",
    "print(f1_score(y_test,predict_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d-2: Decide on an appropriate threshold M for Bag of Words Model.\n",
    "\n",
    "# 1.min_df of BOW - LogisticRegression\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f1_score_list = []\n",
    "m_list = list(range(1,11))\n",
    "\n",
    "for m in m_list:\n",
    "    vectorizer = CountVectorizer(min_df=m,binary=True) \n",
    "    train_bow_vectors = vectorizer.fit_transform(train_corpus) \n",
    "    train_bow_vectors = train_bow_vectors.toarray()    \n",
    "    test_corpus = test_pre\n",
    "    test_bow_vectors = vectorizer.transform(test_corpus) \n",
    "    test_bow_vectors = test_bow_vectors.toarray()\n",
    "    \n",
    "    LR = LogisticRegression()\n",
    "    LR.fit(train_bow_vectors,y_train)\n",
    "    predict_lr=LR.predict(test_bow_vectors)\n",
    "    \n",
    "    f1 = f1_score(y_test,predict_lr)\n",
    "    f1_score_list.append(f1)\n",
    "    \n",
    "print(f1_score_list)\n",
    "max_f1 = max(f1_score_list)\n",
    "print ('Max F1 Score =', max_f1)\n",
    "print ('best threshold M =',f1_score_list.index(max_f1) + 1)\n",
    "\n",
    "#best threshold M=1\n",
    "#plot\n",
    "a1 = m_list\n",
    "b1 = f1_score_list\n",
    "plt.figure(figsize=(15,5)) \n",
    "plt.plot(a1,b1,'o-',linewidth=1)   \n",
    "plt.xlabel(\"min_df\") \n",
    "plt.ylabel(\"F1 Score\")  \n",
    "plt.title(\"min_df of BOW - LogisticRegression\") \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d-2: Decide on an appropriate threshold M for Bag of Words Model.\n",
    "\n",
    "# 2.min_df of BOW - Linear SVM\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f1_score_list = []\n",
    "m_list = list(range(1,11))\n",
    "\n",
    "for m in m_list:\n",
    "    vectorizer = CountVectorizer(min_df=m,binary=True) \n",
    "    train_bow_vectors = vectorizer.fit_transform(train_corpus) \n",
    "    train_bow_vectors = train_bow_vectors.toarray()\n",
    "    test_corpus = test_pre\n",
    "    test_bow_vectors = vectorizer.transform(test_corpus) \n",
    "    test_bow_vectors = test_bow_vectors.toarray()\n",
    "    \n",
    "    lsvm_model=LinearSVC(C=0.1)\n",
    "    lsvm_model.fit(train_bow_vectors,y_train)\n",
    "    predict_lsvm=lsvm_model.predict(test_bow_vectors)\n",
    "    \n",
    "    f1 = f1_score(y_test,predict_lsvm)\n",
    "    f1_score_list.append(f1)\n",
    "    \n",
    "print(f1_score_list)\n",
    "max_f1 = max(f1_score_list)\n",
    "print ('Max F1 Score =', max_f1)\n",
    "print ('best threshold M =',f1_score_list.index(max_f1) + 1)\n",
    "\n",
    "#best threshold M=1\n",
    "#plot\n",
    "a2 = m_list\n",
    "b2 = f1_score_list\n",
    "plt.figure(figsize=(15,5)) \n",
    "plt.plot(a2,b2,'o-',linewidth=1)   \n",
    "plt.xlabel(\"min_df\") \n",
    "plt.ylabel(\"F1 Score\")  \n",
    "plt.title(\"min_df of BOW - Linear SVM\") \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d-2: Decide on an appropriate threshold M for Bag of Words Model.\n",
    "\n",
    "# 3.min_df of BOW - Bernoulli NaiveBayes\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f1_score_list = []\n",
    "m_list = list(range(1,11))\n",
    "\n",
    "for m in m_list:\n",
    "    vectorizer = CountVectorizer(min_df=m,binary=True) \n",
    "    train_bow_vectors = vectorizer.fit_transform(train_corpus) \n",
    "    train_bow_vectors = train_bow_vectors.toarray()\n",
    "    test_corpus = test_pre\n",
    "    test_bow_vectors = vectorizer.transform(test_corpus) \n",
    "    test_bow_vectors = test_bow_vectors.toarray()\n",
    "            \n",
    "    BernoulliNB = Bernoulli_NaiveBayes()\n",
    "    BernoulliNB.train(train_bow_vectors,y_train)\n",
    "    y_pred = BernoulliNB.predict(test_bow_vectors)\n",
    "    \n",
    "    f1 = BernoulliNB.cal_f1_score(y_test,y_pred)\n",
    "    f1_score_list.append(f1)\n",
    "    \n",
    "print(f1_score_list)\n",
    "max_f1 = max(f1_score_list)\n",
    "print ('Max F1 Score =', max_f1)\n",
    "print ('best threshold M =',f1_score_list.index(max_f1) + 1)\n",
    "\n",
    "#best threshold M=3\n",
    "#plot\n",
    "a2 = m_list\n",
    "b2 = f1_score_list\n",
    "plt.figure(figsize=(15,5)) \n",
    "plt.plot(a2,b2,'o-',linewidth=1)   \n",
    "plt.xlabel(\"min_df\") \n",
    "plt.ylabel(\"F1 Score\")  \n",
    "plt.title(\"min_df of BOW - Bernoulli NaiveBayes\") \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d-2: Decide on an appropriate threshold M for Bag of Words Model.\n",
    "\n",
    "# 4.min_df of BOW - non-linear SVM\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f1_score_list = []\n",
    "m_list = list(range(1,11))\n",
    " \n",
    "for m in m_list:\n",
    "    vectorizer = CountVectorizer(min_df=m,binary=True) \n",
    "    train_bow_vectors = vectorizer.fit_transform(train_corpus) \n",
    "    train_bow_vectors = train_bow_vectors.toarray()\n",
    "    test_corpus = test_pre\n",
    "    test_bow_vectors = vectorizer.transform(test_corpus) \n",
    "    test_bow_vectors = test_bow_vectors.toarray()\n",
    "        \n",
    "    SVM=SVC(C=1,kernel='rbf',gamma=0.1)\n",
    "    SVM.fit(train_bow_vectors,y_train)\n",
    "    predict_svm=SVM.predict(test_bow_vectors)\n",
    "    \n",
    "    f1 = f1_score(y_test,predict_svm)\n",
    "    f1_score_list.append(f1)\n",
    "    \n",
    "print(f1_score_list)\n",
    "max_f1 = max(f1_score_list)\n",
    "print ('Max F1 Score =', max_f1)\n",
    "print ('best threshold M =',f1_score_list.index(max_f1) + 1)\n",
    "\n",
    "#best threshold M=5\n",
    "#plot\n",
    "a4 = m_list\n",
    "b4 = f1_score_list\n",
    "plt.figure(figsize=(15,5)) \n",
    "plt.plot(a4,b4,'o-',linewidth=1)   \n",
    "plt.xlabel(\"min_df\") \n",
    "plt.ylabel(\"F1 Score\")  \n",
    "plt.title(\"min_df of BOW - non-linear SVM\") \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i-3: Decide on an appropriate threshold M for N-gram Model\n",
    "\n",
    "# 1.min_df of N-gram - LogisticRegression\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f1_score_list = []\n",
    "m_list = list(range(1,11))\n",
    "\n",
    "for m in m_list:\n",
    "    vectorizer = CountVectorizer(min_df=m,ngram_range=(1,2),binary=True)\n",
    "    train_ng_vectors = vectorizer.fit_transform(train_corpus) \n",
    "    train_ng_vectors = train_ng_vectors.toarray()    \n",
    "    test_corpus = test_pre\n",
    "    test_ng_vectors = vectorizer.transform(test_corpus) \n",
    "    test_ng_vectors = test_ng_vectors.toarray()\n",
    "    \n",
    "    LR = LogisticRegression()\n",
    "    LR.fit(train_ng_vectors,y_train)\n",
    "    predict_lr=LR.predict(test_ng_vectors)\n",
    "    \n",
    "    f1 = f1_score(y_test,predict_lr)\n",
    "    f1_score_list.append(f1)\n",
    "    \n",
    "print(f1_score_list)\n",
    "max_f1 = max(f1_score_list)\n",
    "print ('Max F1 Score =', max_f1)\n",
    "print ('best threshold M =',f1_score_list.index(max_f1) + 1)\n",
    "\n",
    "#best threshold M=3\n",
    "#plot\n",
    "a1 = m_list\n",
    "b1 = f1_score_list\n",
    "plt.figure(figsize=(15,5)) \n",
    "plt.plot(a1,b1,'o-',linewidth=1)   \n",
    "plt.xlabel(\"min_df\") \n",
    "plt.ylabel(\"F1 Score\")  \n",
    "plt.title(\"min_df of N-gram - LogisticRegression\") \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i-3: Decide on an appropriate threshold M for N-gram Model\n",
    "\n",
    "# 2.min_df of N-gram - Linear SVM\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f1_score_list = []\n",
    "m_list = list(range(1,11))\n",
    "\n",
    "for m in m_list:\n",
    "    vectorizer = CountVectorizer(min_df=m,ngram_range=(1,2),binary=True) \n",
    "    train_ng_vectors = vectorizer.fit_transform(train_corpus) \n",
    "    train_ng_vectors = train_ng_vectors.toarray()\n",
    "    test_corpus = test_pre\n",
    "    test_ng_vectors = vectorizer.transform(test_corpus) \n",
    "    test_ng_vectors = test_ng_vectors.toarray()\n",
    "    \n",
    "    lsvm_model=LinearSVC(C=0.1)\n",
    "    lsvm_model.fit(train_ng_vectors,y_train)\n",
    "    predict_lsvm=lsvm_model.predict(test_ng_vectors)\n",
    "    \n",
    "    f1 = f1_score(y_test,predict_lsvm)\n",
    "    f1_score_list.append(f1)\n",
    "    \n",
    "print(f1_score_list)\n",
    "max_f1 = max(f1_score_list)\n",
    "print ('Max F1 Score =', max_f1)\n",
    "print ('best threshold M =',f1_score_list.index(max_f1) + 1)\n",
    "\n",
    "#best threshold M=3\n",
    "#plot\n",
    "a2 = m_list\n",
    "b2 = f1_score_list\n",
    "plt.figure(figsize=(15,5)) \n",
    "plt.plot(a2,b2,'o-',linewidth=1)   \n",
    "plt.xlabel(\"min_df\") \n",
    "plt.ylabel(\"F1 Score\")  \n",
    "plt.title(\"min_df of N-gram - Linear SVM\") \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i-3: Decide on an appropriate threshold M for N-gram Model\n",
    "\n",
    "# 3.min_df of N-gram - Bernoulli NaiveBayes\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f1_score_list = []\n",
    "m_list = list(range(1,11))\n",
    "\n",
    "for m in m_list:\n",
    "    vectorizer = CountVectorizer(min_df=m,ngram_range=(1,2),binary=True) \n",
    "    train_ng_vectors = vectorizer.fit_transform(train_corpus) \n",
    "    train_ng_vectors = train_ng_vectors.toarray()\n",
    "    test_corpus = test_pre\n",
    "    test_ng_vectors = vectorizer.transform(test_corpus) \n",
    "    test_ng_vectors = test_ng_vectors.toarray()\n",
    "            \n",
    "    BernoulliNB = Bernoulli_NaiveBayes()\n",
    "    BernoulliNB.train(train_ng_vectors,y_train)\n",
    "    y_pred = BernoulliNB.predict(test_ng_vectors)\n",
    "    \n",
    "    f1 = BernoulliNB.cal_f1_score(y_test,y_pred)\n",
    "    f1_score_list.append(f1)\n",
    "    \n",
    "print(f1_score_list)\n",
    "max_f1 = max(f1_score_list)\n",
    "print ('Max F1 Score =', max_f1)\n",
    "print ('best threshold M =',f1_score_list.index(max_f1) + 1)\n",
    "\n",
    "#best threshold M=5\n",
    "#plot\n",
    "a2 = m_list\n",
    "b2 = f1_score_list\n",
    "plt.figure(figsize=(15,5)) \n",
    "plt.plot(a2,b2,'o-',linewidth=1)   \n",
    "plt.xlabel(\"min_df\") \n",
    "plt.ylabel(\"F1 Score\")  \n",
    "plt.title(\"min_df of N-gram - Bernoulli NaiveBayes\") \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i-3: Decide on an appropriate threshold M for N-gram Model\n",
    "\n",
    "# 4.min_df of N-gram - non-linear SVM\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f1_score_list = []\n",
    "m_list = list(range(1,11))\n",
    "\n",
    "for m in m_list:\n",
    "    vectorizer = CountVectorizer(min_df=m,ngram_range=(1,2),binary=True) \n",
    "    train_ng_vectors = vectorizer.fit_transform(train_corpus) \n",
    "    train_ng_vectors = train_ng_vectors.toarray()\n",
    "    test_corpus = test_pre\n",
    "    test_ng_vectors = vectorizer.transform(test_corpus) \n",
    "    test_ng_vectors = test_ng_vectors.toarray()\n",
    "        \n",
    "    SVM=SVC(C=1,kernel='rbf',gamma=0.1)\n",
    "    SVM.fit(train_ng_vectors,y_train)\n",
    "    predict_svm=SVM.predict(test_ng_vectors)\n",
    "    \n",
    "    f1 = f1_score(y_test,predict_svm)\n",
    "    f1_score_list.append(f1)\n",
    "    \n",
    "print(f1_score_list)\n",
    "max_f1 = max(f1_score_list)\n",
    "print ('Max F1 Score =', max_f1)\n",
    "print ('best threshold M =',f1_score_list.index(max_f1) + 1)\n",
    "\n",
    "#best threshold M=3\n",
    "#plot\n",
    "a4 = m_list\n",
    "b4 = f1_score_list\n",
    "plt.figure(figsize=(15,5)) \n",
    "plt.plot(a4,b4,'o-',linewidth=1)   \n",
    "plt.xlabel(\"min_df\") \n",
    "plt.ylabel(\"F1 Score\")  \n",
    "plt.title(\"min_df of N-gram - non-linear SVM\") \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question l: Reflecting on interpretability.\n",
    "\n",
    "Description: Suppose that you were constructing a model for this task as part of a consulting job, where you not only cared about classification performance, but wanted an interpetable model, such that you could explain to your clients how it made its decisions, and they could trust the model.  \n",
    "\n",
    "l-1: Would you still choose the same approach, or a different one? Discuss why or why not, which approach you think would be best in this setting.\n",
    "\n",
    "answer: \n",
    "\n",
    "Theoretically speaking, among the four models, Bernoulli Naive Bayes model has the best interpretability, Logistic Regression model has the second-best interpretability, Linear SVM model has the third-best interpretability, and Non-linear SVM model has the worst interpretability.\n",
    "\n",
    "First, Naive Bayes and logistic regression are both linear models, in which feature weights correspond directly to the importance of features, so it is easy to understand what the model has learned. Both models are based on conditional probabilities, so they both have good interpretability for the final results of different classes.\n",
    "\n",
    "Second, Naive Bayes model is derived from the total probability formula, and each step has the probability deduction. It realizes classification by calculating the probability of features. Because constraints of Naive Bayes are stricter than logistic regression, the relevant parameters of Naive Bayes are more clear (i.e. have fixed forms). It directly counts the logical occurrence ratio of each feature as a weight. However, the parameters obtained by logistic regression do not have clear forms (because it does not have such strict constraints as Naive Bayes). It can obtain the weight of each feature through optimization methods such as gradient descent method to see which features are more important.\n",
    "\n",
    "Third, SVM model has a theoretical derivation process, but its interpretability is not very strong. It's not as intuitive as Naive Bayes, logistic regression and decision tree. Relatively speaking, if using a linear kernel, its interpretability is slightly better, similar to linear regression; if using a nonlinear kernel, such as RBF, its interpretability is very poor.\n",
    "\n",
    "In conclusion, interpretability is an essential characteristic of a reliable system and an important influence factor in clients' trust in the model/technique. **Given that the Bernoulli Naive Bayes model has not only the best performance but also the best interpretability among the four models used for this task, I would choose Bernoulli Naive Bayes model as our best approach.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
