{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "<class 'numpy.ndarray'>\n",
      "['aa', 'aba', 'abandon', 'abbswinston', 'abc', 'abcnew', 'abil', 'abl', 'ablaz', 'about', 'absolut', 'abstorm', 'abus', 'accept', 'access', 'accid', 'accident', 'accionempresa', 'accord', 'account', 'accus', 'achiev', 'acid', 'acr', 'across', 'act', 'action', 'activ', 'actual', 'ad', 'add', 'address', 'admit', 'adopt', 'adult', 'advanc', 'advisori', 'af', 'affect', 'affili', 'afghan', 'afghanistan', 'afp', 'afraid', 'africa', 'after', 'afternoon', 'aftershock', 'ag', 'again']\n",
      "[('ash', 169), ('australia', 192), ('collaps', 532), ('trent', 2721), ('bridg', 355), ('among', 99), ('worst', 2941), ('histori', 1240), ('england', 859), ('bundl', 381), ('great', 1140), ('michigan', 1652), ('techniqu', 2592), ('camp', 408), ('thank', 2617), ('hail', 1171), ('cnn', 523), ('tennesse', 2602), ('movi', 1714), ('theater', 2621), ('shoot', 2346), ('suspect', 2555), ('kill', 1428), ('polic', 1984), ('still', 2494), ('riot', 2205), ('coupl', 594), ('hour', 1264), ('left', 1483), ('to', 2665), ('up', 2788), ('class', 503), ('crack', 601), ('the', 2620), ('path', 1917), ('thi', 2631), ('morn', 1700), ('beach', 245), ('run', 2238), ('surfac', 2549), ('wound', 2945), ('right', 2203), ('knee', 1438), ('expert', 914), ('franc', 1042), ('begin', 262), ('examin', 897), ('airplan', 64), ('debri', 667), ('found', 1035)]\n",
      "[ 3  8  8 ...  6  6 24]\n",
      "(5329, 2991)\n",
      "total number of features in trainset: 2991\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "<class 'numpy.ndarray'>\n",
      "['aa', 'aba', 'abandon', 'abbswinston', 'abc', 'abcnew', 'abil', 'abl', 'ablaz', 'about', 'absolut', 'abstorm', 'abus', 'accept', 'access', 'accid', 'accident', 'accionempresa', 'accord', 'account', 'accus', 'achiev', 'acid', 'acr', 'across', 'act', 'action', 'activ', 'actual', 'ad', 'add', 'address', 'admit', 'adopt', 'adult', 'advanc', 'advisori', 'af', 'affect', 'affili', 'afghan', 'afghanistan', 'afp', 'afraid', 'africa', 'after', 'afternoon', 'aftershock', 'ag', 'again']\n",
      "[('ash', 169), ('australia', 192), ('collaps', 532), ('trent', 2721), ('bridg', 355), ('among', 99), ('worst', 2941), ('histori', 1240), ('england', 859), ('bundl', 381), ('great', 1140), ('michigan', 1652), ('techniqu', 2592), ('camp', 408), ('thank', 2617), ('hail', 1171), ('cnn', 523), ('tennesse', 2602), ('movi', 1714), ('theater', 2621), ('shoot', 2346), ('suspect', 2555), ('kill', 1428), ('polic', 1984), ('still', 2494), ('riot', 2205), ('coupl', 594), ('hour', 1264), ('left', 1483), ('to', 2665), ('up', 2788), ('class', 503), ('crack', 601), ('the', 2620), ('path', 1917), ('thi', 2631), ('morn', 1700), ('beach', 245), ('run', 2238), ('surfac', 2549), ('wound', 2945), ('right', 2203), ('knee', 1438), ('expert', 914), ('franc', 1042), ('begin', 262), ('examin', 897), ('airplan', 64), ('debri', 667), ('found', 1035)]\n",
      "[ 0  6  6 ...  0  0 11]\n",
      "(2284, 2991)\n",
      "total number of features in dev set: 2991\n"
     ]
    }
   ],
   "source": [
    "%run pre_processing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e-1: implement the BernoulliNB Naive Bayes classifier, without using any existing machine learning libraries.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class Bernoulli_NaiveBayes:\n",
    "\n",
    "    def __init__(self):   \n",
    "        self.alpha = 1 # set smoothing factor=1(Laplace Smoothing), to avoid zero probability problems  \n",
    "\n",
    "    def _cal_prior_prob_log(self, y, classes): # calculate the logarithm of prior probability of each class, P(y=c_k)\n",
    "        self.classes = np.unique(y)\n",
    "        class_num = len(self.classes) #count the number of possible types of y\n",
    "        sample_num = len(y)\n",
    "        \n",
    "        c_num = np.count_nonzero(y == classes[:, None], axis=1) #count sample amount of each class\n",
    "        prior_prob = (c_num + self.alpha) / (sample_num + class_num * self.alpha) #calculate prior probabilities(add smoothing correction)\n",
    "        prior_prob_log = np.log(prior_prob) #calculate logarithm\n",
    "        \n",
    "        return prior_prob_log\n",
    "    \n",
    "    def _cal_condi_prob_log(self, X, y, classes): #calculate the logarithm of all conditional probabilities P(x^(j)|y=c_k)\n",
    "        \n",
    "        n = (X.shape)[1]\n",
    "        K = len(classes)\n",
    "        \n",
    "        #create an empty multidimensional array\n",
    "        #prob_log: logarithmic matrix of two conditional probabilities\n",
    "        condi_prob_log = np.empty((2, K, n)) \n",
    "        \n",
    "        for k, c in enumerate(classes):\n",
    "            X_c = X[np.equal(y, c)] #acquire all samples of class c_k\n",
    "            total_num = len(X_c)\n",
    "            num_f1 = np.count_nonzero(X_c, axis=0) #count the number of samples of which feature value is 1\n",
    "            condi_prob_f1 = (num_f1 + self.alpha) / (total_num + self.alpha * 2) #calculate conditional probability P(x^(j)=1|y=c_k)\n",
    "            \n",
    "            #calculate and store logarithm into matrix\n",
    "            #prob_log[0]: store all values of log(P(x^(j)=0|y=c_k))\n",
    "            #prob_log[1]: store all values of log(P(x^(j)=1|y=c_k))\n",
    "            condi_prob_log[0, k] = np.log(1 - condi_prob_f1) \n",
    "            condi_prob_log[1, k] = np.log(condi_prob_f1) \n",
    "            \n",
    "        return condi_prob_log\n",
    "   \n",
    "    def train(self, x_train, y_train): #train the model\n",
    "        self.classes = np.unique(y_train) #acquire all classes  \n",
    "        self.prior_prob_log = self._cal_prior_prob_log(y_train, self.classes) #calculate and store the logarithm of all prior probabilities\n",
    "        self.condi_prob_log = self._cal_condi_prob_log(x_train, y_train, self.classes) #calculate and store the logarithm of all conditional probabilities\n",
    "\n",
    "    def _predict_single_sample(self, x): #predict the label of single sample\n",
    "\n",
    "        K = len(self.classes)\n",
    "        po_prob_log = np.empty(K) #create an empty multidimensional array\n",
    "        \n",
    "        index_f1 = x == 1 #acquire index of feature value=1 \n",
    "        index_f0 = ~index_f1 #acquire index of feature value=0\n",
    "\n",
    "        for k in range(K): #iterate each class\n",
    "            #calculate the logarithm of the numerator of the posterior probability\n",
    "            po_prob_log[k] = self.prior_prob_log[k] \\\n",
    "                                + np.sum(self.condi_prob_log[0, k][index_f0]) \\\n",
    "                                + np.sum(self.condi_prob_log[1, k][index_f1])\n",
    "\n",
    "        label = np.argmax(po_prob_log) #get the class with the highest posterior probability\n",
    "        return label\n",
    "\n",
    "    def predict(self, X): #predict samples (include single sample)\n",
    "        \n",
    "        if X.ndim == 1: #if only predict single sample (the dimension of the array = 1), invoke _predict_single_sample()\n",
    "            return self._predict_single_sample(X) \n",
    "        else:\n",
    "            #if predict multiple samples, loop call _predict_single_sample() and return a list of the predicted results \n",
    "            labels = []\n",
    "            for j in range(X.shape[0]):\n",
    "                label = self._predict_single_sample(X[j])\n",
    "                labels.append(label)\n",
    "            return labels\n",
    "        \n",
    "    def cal_f1_score(self,true,predict):\n",
    "        \n",
    "        true = list(true)\n",
    "        num = len(true)\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        TN = 0\n",
    "        FN = 0\n",
    "        \n",
    "        for i in range(num):               \n",
    "            if true[i] != predict[i]:\n",
    "                if true[i] == 1:\n",
    "                    FN += 1\n",
    "                else:\n",
    "                    FP += 1\n",
    "            else:\n",
    "                if true[i] == 1:\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    TN += 1\n",
    "\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        F1_Score = 2 * (precision * recall) / (precision + recall)\n",
    "        return F1_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7611518915866743\n"
     ]
    }
   ],
   "source": [
    "# e-2: Train the Bernoulli_NaiveBayes classifier on the train set, and report its mean F 1-score on the dev set.\n",
    "\n",
    "x_train = train_bow_vectors\n",
    "y_train = np.array(y_train)\n",
    "x_test = test_bow_vectors\n",
    "\n",
    "BernoulliNB = Bernoulli_NaiveBayes()\n",
    "BernoulliNB.train(x_train,y_train)\n",
    "y_pred = BernoulliNB.predict(x_test)\n",
    "\n",
    "print (BernoulliNB.cal_f1_score(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
